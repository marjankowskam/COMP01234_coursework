{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from networkx.algorithms import community\n",
    "\n",
    "import community as community_louvain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('data/primaryschool.csv', header=None, delimiter='\\t', names = ['time', 'u', 'v', 'grade_u', 'grade_v'])\n",
    "print(df_original.head())\n",
    "\n",
    "metadata = pd.read_csv('data/metadata.txt', header=None, delimiter='\\t', names = ['id', 'grade', 'gender'])\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by source, target, and timestamp\n",
    "df_original = df_original.sort_values(by=['u', 'v', 'time'])\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "df = []\n",
    "\n",
    "# Iterate through the dataframe to calculate weights\n",
    "for (u, v), group in df_original.groupby(['u', 'v']):\n",
    "    timestamps = group['time'].tolist()\n",
    "    weight = 1\n",
    "    first_time = timestamps[0]\n",
    "    for i in range(1, len(timestamps)):\n",
    "        if timestamps[i] == timestamps[i-1] + 20:\n",
    "            weight += 1\n",
    "        else:\n",
    "            df.append({'u': u, 'v': v, 'weight': weight, 'time': first_time})\n",
    "            weight = 1\n",
    "            first_time = timestamps[i]\n",
    "    df.append({'u': u, 'v': v, 'weight': weight, 'time': first_time})\n",
    "\n",
    "# Create a new dataframe from the result\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_dict = {\"1A\": \"red\", \"1B\": \"red\", \"2A\": \"orange\", \"2B\": \"orange\", \"3A\": \"gray\", \"3B\": \"gray\", \"4A\": \"cyan\", \"4B\": \"cyan\", \"5A\": \"blue\", \"5B\": \"blue\", \"Teachers\": \"black\"}\n",
    "grade_dict_more = {\"1A\": \"firebrick\", \"1B\": \"red\", \"2A\": \"orange\", \"2B\": \"sandybrown\", \"3A\": \"slategray\", \"3B\": \"gray\", \"4A\": \"darkturquoise\", \"4B\": \"cyan\", \"5A\": \"cornflowerblue\", \"5B\": \"blue\", \"Teachers\": \"black\"}\n",
    "\n",
    "node_grade = {}\n",
    "node_gender = {}\n",
    "for _, row in metadata.iterrows():\n",
    "    node_grade[row['id']] = row['grade']\n",
    "    node_gender[row['id']] = row['gender']\n",
    "\n",
    "gender_dict = {\"M\": \"blue\", \"F\": \"magenta\", \"Unknown\": \"gray\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for _, row in metadata.iterrows():\n",
    "    if row['grade'] != \"Teachers\":\n",
    "        G.add_node(row['id'], color=grade_dict_more[row['grade']])\n",
    "\n",
    "for _, edge in df.iterrows():\n",
    "    if node_grade[edge['u']] != \"Teachers\" and node_grade[edge['v']] != \"Teachers\":\n",
    "        G.add_edge(edge['u'], edge['v'], weight=edge['weight'], time=edge['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = {grade: metadata[metadata['grade'] == grade]['id'].tolist() for grade in metadata['grade'].unique()}\n",
    "group = {'1A': group['1A'], '1B': group['1B'], '5A': group['5A'], '5B': group['5B']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_min = 31220\n",
    "d1_max = 62300\n",
    "\n",
    "d2_min = 117240\n",
    "d2_max = 148120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_break = {\"1A\": \"10:40:00\", \"1B\": \"10:10:00\", \"5A\": \"09:45:00\", \"5B\": \"09:45:00\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph_per_community(G, pos, node_colors, communities):\n",
    "    fig, axes = plt.subplots(1, len(communities), figsize=(4*len(communities), 4))\n",
    "    print(len(communities))\n",
    "    if len(communities) == 1:\n",
    "        axes = [axes]  # Ensure axes is iterable\n",
    "\n",
    "    for ax, community in zip(axes, communities):\n",
    "        subgraph = G.subgraph(community)\n",
    "        nx.draw(subgraph, pos, ax=ax, node_color=[grade_dict_more[node_grade[node]]for node in community], with_labels=True, node_size=100, edge_color='gray')\n",
    "        ax.set_title(f\"Community {communities.index(community) + 1}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_time(timestamp):\n",
    "\n",
    "    is_day_2 = (timestamp > 117000)\n",
    "    # Convert timestamp to seconds since start of the day\n",
    "    seconds_since_start = (timestamp - (117240 if is_day_2 else d1_min))\n",
    "\n",
    "    # Calculate hours, minutes, and seconds\n",
    "    hours = 8 + (seconds_since_start // 3600)\n",
    "    minutes = (30 if is_day_2 else 45) + ((seconds_since_start % 3600) // 60)\n",
    "    seconds = seconds_since_start % 60\n",
    "    # Adjust for overflow in minutes\n",
    "    if minutes >= 60:\n",
    "        hours += 1\n",
    "        minutes -= 60\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
    "\n",
    "def time_to_timestamp(time_str, day=1):\n",
    "    # Parse the time string\n",
    "    hours, minutes, seconds = map(int, time_str.split(':'))\n",
    "    # Calculate total seconds since start of the day\n",
    "    total_seconds = (hours - 8) * 3600 + (minutes - 45) * 60 + seconds\n",
    "    # Convert to timestamp\n",
    "    timestamp = (d1_min if day==1 else 117240) + total_seconds\n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_temporal_adjacency(df):\n",
    "    \"\"\"Preprocess to create a dictionary of adjacency lists by time.\"\"\"\n",
    "    temporal_adj = defaultdict(lambda: defaultdict(list))\n",
    "    for _, row in df.iterrows():\n",
    "        temporal_adj[row['time']][row['u']].append(row['v'])\n",
    "        temporal_adj[row['time']][row['v']].append(row['u'])\n",
    "    return temporal_adj\n",
    "\n",
    "def temporal_distance_optimized(temporal_adj, G, source, tmin, tmax, h):\n",
    "    \"\"\"\n",
    "    Optimized temporal distance calculation.\n",
    "    \"\"\"\n",
    "    # Initialize D, T, and R\n",
    "    D = {node: float('inf') for node in G.nodes()}  # Distance\n",
    "    T = {node: float('inf') for node in G.nodes()}  # First time of reachability\n",
    "    R = {node: False for node in G.nodes()}  # Reachable\n",
    "\n",
    "    D[source] = 0\n",
    "    T[source] = 0\n",
    "    R[source] = True\n",
    "\n",
    "    # Iterate over time windows\n",
    "    for t in range(tmin, tmax + 1, 20):\n",
    "        stack = [(node, 0) for node in G.nodes() if R[node]]\n",
    "\n",
    "        while stack:\n",
    "            node, depth = stack.pop()\n",
    "            if depth < h:\n",
    "                neighbors_t = temporal_adj[t].get(node, [])\n",
    "                for neighbor in neighbors_t:\n",
    "                    if not R[neighbor]:\n",
    "                        R[neighbor] = True\n",
    "                        T[neighbor] = (t - tmin) / 20\n",
    "                        D[neighbor] = D[node] + 1\n",
    "                        stack.append((neighbor, depth + 1))\n",
    "                    elif T[neighbor] == (t - tmin) / 20 and D[neighbor] > D[node] + 1:\n",
    "                        D[neighbor] = D[node] + 1\n",
    "                        stack.append((neighbor, depth + 1))\n",
    "\n",
    "    return T, D\n",
    "\n",
    "# # Example usage with preprocessing\n",
    "# tmin = df['time'].min()\n",
    "# tmax = tmin + 20 * 180\n",
    "# h = 3  # Horizon\n",
    "\n",
    "\n",
    "def run_temporal_distance_analysis(tmin_dict, tmax_dict, h):\n",
    "    results = []\n",
    "\n",
    "    for grade, nodes in group.items():\n",
    "        subgraph = G.subgraph(nodes)\n",
    "        df_group = df_original[df_original['u'].isin(nodes) & df_original['v'].isin(nodes)]\n",
    "        temporal_adj = preprocess_temporal_adjacency(df_group)\n",
    "\n",
    "        # Filter nodes that appear at least once in the given timeframe\n",
    "        nodes_in_timeframe = set(df_group[(df_group['time'] >= tmin_dict[grade]) & (df_group['time'] <= tmax_dict[grade])]['u']).union(\n",
    "            set(df_group[(df_group['time'] >= tmin_dict[grade]) & (df_group['time'] <= tmax_dict[grade])]['v'])\n",
    "        )\n",
    "        nodes = list(nodes_in_timeframe)\n",
    "\n",
    "        T = np.zeros((len(nodes), len(nodes)))\n",
    "        D = np.zeros((len(nodes), len(nodes)))\n",
    "\n",
    "        tmin = tmin_dict[grade]\n",
    "        tmax = tmax_dict[grade]\n",
    "\n",
    "        for node_id, source in enumerate(nodes):\n",
    "            temporal_distances, node_distances = temporal_distance_optimized(\n",
    "                temporal_adj, subgraph, source, tmin, tmax, h\n",
    "            )\n",
    "            T[node_id, :] = [temporal_distances[node] for node in nodes]\n",
    "            D[node_id, :] = [node_distances[node] for node in nodes]\n",
    "\n",
    "        inf_temporal = np.sum(np.isinf(T))\n",
    "        inf_node = np.sum(np.isinf(D))\n",
    "\n",
    "        avg_temporal = np.sum(T[np.isfinite(T)]) / (T.size - inf_temporal)\n",
    "        avg_node = np.sum(D[np.isfinite(D)]) / (D.size - inf_node)\n",
    "        results.append({\n",
    "            'grade': grade,\n",
    "            'inf_temporal': inf_temporal,\n",
    "            'inf_node': inf_node,\n",
    "            'avg_temporal': avg_temporal,\n",
    "            'avg_node': avg_node,\n",
    "            'efficiency': np.sum(1/T[np.isfinite(T)]),\n",
    "            'T_matrix': T,\n",
    "            'D_matrix': D\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# # Example usage with preprocessing\n",
    "# tmin_dict = {'1A': 36020, '1B': 36020, '5A': 36020, '5B': 36020}\n",
    "# tmax_dict = {'1A': d1_max, '1B': d1_max, '5A': d1_max, '5B': d1_max}\n",
    "# h = 3  # Horizon\n",
    "\n",
    "# all_results = []\n",
    "# bin_size = 1800  # 30 minutes in seconds\n",
    "\n",
    "# for increase in range(0, tmax_dict['1A']-tmin_dict['1A'], bin_size):\n",
    "\n",
    "#     tmin_dict_here = {x: d1_min + increase for x in group.keys()}\n",
    "#     tmax_dict_here = {x: d1_min + 30*60 + increase for x in group.keys()}\n",
    "\n",
    "#     results = run_temporal_distance_analysis(tmin_dict_here, tmax_dict_here, h)\n",
    "#     all_results.extend(results)\n",
    "#     print(f'time {d1_min + increase} done.')\n",
    "\n",
    "\n",
    "\n",
    "# # Convert results to a DataFrame for easier plotting\n",
    "# results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# # Make a scatterplot of the results\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create a scatter plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for grade in results_df['grade'].unique():\n",
    "#     subset = results_df[results_df['grade'] == grade]\n",
    "#     plt.scatter(subset['avg_temporal'], subset['inf_temporal'], label=grade)\n",
    "\n",
    "# plt.xlabel('Average Temporal Distance')\n",
    "# plt.ylabel('Number of Infinite Temporal Distances')\n",
    "# plt.title('Scatter plot of Average Temporal Distance vs Number of Infinite Temporal Distances')\n",
    "# plt.legend(title='Grade')\n",
    "# plt.show()\n",
    "\n",
    "# # Create a scatter plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for grade in results_df['grade'].unique():\n",
    "#     subset = results_df[results_df['grade'] == grade]\n",
    "#     plt.scatter(subset['avg_node'], subset['inf_node'], label=grade)\n",
    "\n",
    "# plt.xlabel('Average Node-Temporal Distance')\n",
    "# plt.ylabel('Number of Infinite Node-Temporal Distances')\n",
    "# plt.title('Scatter plot of Average Temporal Distance vs Number of Infinite Temporal Distances')\n",
    "# plt.legend(title='Grade')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
